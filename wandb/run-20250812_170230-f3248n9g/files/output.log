
--- Epoch 1/50 ---
Training: 100%|████████████████████████████████████████████████████████████████████████| 750/750 [28:14<00:00,  2.26s/it, avg_loss=156110.3587]
Evaluating:   0%|                                                                                                      | 0/188 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "c:\Users\carlo\OneDrive\Escritorio\ProyectoLAISTA\train.py", line 126, in <module>
    main()
  File "c:\Users\carlo\OneDrive\Escritorio\ProyectoLAISTA\train.py", line 99, in main
    val_loss = evaluate(model, val_loader, loss_fn, device)
  File "c:\Users\carlo\OneDrive\Escritorio\ProyectoLAISTA\src\train_test.py", line 79, in evaluate
    img_hat = model(y, x0=x0)
  File "C:\Users\carlo\anaconda3\envs\laista\lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\carlo\anaconda3\envs\laista\lib\site-packages\torch\nn\modules\module.py", line 1857, in _call_impl
    return inner()
  File "C:\Users\carlo\anaconda3\envs\laista\lib\site-packages\torch\nn\modules\module.py", line 1805, in inner
    result = forward_call(*args, **kwargs)
  File "c:\Users\carlo\OneDrive\Escritorio\ProyectoLAISTA\src\model.py", line 217, in forward
    x = z - self.alpha * self.fidelity.grad(z, y, self.H)
  File "c:\Users\carlo\OneDrive\Escritorio\ProyectoLAISTA\colibri\recovery\terms\fidelity.py", line 52, in grad
    return torch.autograd.grad(norm, x, create_graph=True, grad_outputs=torch.ones_like(norm))[0]
  File "C:\Users\carlo\anaconda3\envs\laista\lib\site-packages\torch\autograd\__init__.py", line 502, in grad
    result = _engine_run_backward(
  File "C:\Users\carlo\anaconda3\envs\laista\lib\site-packages\torch\autograd\graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
